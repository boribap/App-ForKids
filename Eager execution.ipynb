{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로 임포트 \n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서 \n",
    "    - 텐서 : 다차원 배열 \n",
    "    - 넘파이의 ndarray 객체와 비슷 / Tensor 객체는 데이터 타입과 크기를 가짐\n",
    "    - 텐서는 GPU 같은 가속기 메모리에 상주 가능 \n",
    "    \n",
    "    ## 넘파이 호환성\n",
    "        - 텐서플로 연산은 자동적으로 넘파이 배열을 텐서로 변환 -> 텐서는 .numpy() 메서드(method)를 호출하여 넘파이 배열로 변환\n",
    "            --> 해당 변환이 항상 가능한 것은 아님. (메모리 장소가 GPU이냐 아니냐에 따름)\n",
    "            --> GPU를 사용중이었다면 GPU에서 호스트 메모리(넘파이 배열이 항상 저장되는 곳)로의 복사가 필요 \n",
    "        - 넘파이 연산은 자동적으로 텐서를 넘파이 배열로 변환\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor([4 6], shape=(2,), dtype=int32)\n",
      "tf.Tensor(25, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(b'aGVsbG8gd29ybGQ', shape=(), dtype=string)\n",
      "tf.Tensor(13, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 텐서 실습 1 \n",
    "\n",
    "print(tf.add(1, 2))\n",
    "print(tf.add([1, 2], [3, 4]))\n",
    "print(tf.square(5))\n",
    "print(tf.reduce_sum([1, 2, 3]))\n",
    "print(tf.encode_base64(\"hello world\"))\n",
    "\n",
    "# 연산자의 오버로딩(overloding) 또한 지원합니다.\n",
    "print(tf.square(2) + tf.square(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "<dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "# 텐서 실습 2\n",
    "\n",
    "# Tensor 객체는 데이터 타입과 크기를 가짐\n",
    "\n",
    "x = tf.matmul([[1]], [[2, 3]])\n",
    "print(x.shape)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텐서플로 연산은 자동적으로 넘파이 배열을 텐서로 변환합니다.\n",
      "tf.Tensor(\n",
      "[[42. 42. 42.]\n",
      " [42. 42. 42.]\n",
      " [42. 42. 42.]], shape=(3, 3), dtype=float64)\n",
      "그리고 넘파이 연산은 자동적으로 텐서를 넘파이 배열로 변환합니다.\n",
      "[[43. 43. 43.]\n",
      " [43. 43. 43.]\n",
      " [43. 43. 43.]]\n",
      ".numpy() 메서드는 텐서를 넘파이 배열로 변환합니다.\n",
      "[[42. 42. 42.]\n",
      " [42. 42. 42.]\n",
      " [42. 42. 42.]]\n"
     ]
    }
   ],
   "source": [
    "# 넘파이 호환성 실습 1\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "ndarray = np.ones([3, 3])\n",
    "\n",
    "print(\"텐서플로 연산은 자동적으로 넘파이 배열을 텐서로 변환합니다.\")\n",
    "tensor = tf.multiply(ndarray, 42)\n",
    "print(tensor)\n",
    "\n",
    "\n",
    "print(\"그리고 넘파이 연산은 자동적으로 텐서를 넘파이 배열로 변환합니다.\")\n",
    "print(np.add(tensor, 1))\n",
    "\n",
    "print(\".numpy() 메서드는 텐서를 넘파이 배열로 변환합니다.\")\n",
    "print(tensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 가속기 \n",
    "    - 대부분의 텐서플로 연산은 GPU를 사용해 가속화 가능 \n",
    "    - 어떤 주석도 없이 텐서플로는 연산을 위해 자동적으로 CPU 또는 GPU를 사용할 것인지 정함 \n",
    "    \n",
    "    ## 장치 이름\n",
    "        - Tensor.device는 텐서를 구성하고 있는 호스트 장치의 풀네임을 제공\n",
    "        - 이름은 프로그램이 실행중인 호스트의 네트워크 주소 및 해당 호스트 내의 장치와 같은 많은 세부 정보를 인코딩한다\n",
    "        - 텐서가 호스트의 N번째 GPU에 놓여지면 문자열은 GPU:<N>으로 끝납니다.\n",
    "            \n",
    "    ## 명시적 장치 배치\n",
    "        - \"배치(replacement)\"라는 용어는 개별 연산을 실행하기 위해 장치에 할당(배치) 하는 것\n",
    "        - 언급이 없다면 자동으로 결정 but 위의 장치이름(tf.device)를 사용하여 특정 장치에 명시적으로 배치 가능 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 사용이 가능한가 : \n",
      "False\n",
      "텐서가 GPU #0에 있는가 :  \n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# GPU 가속기 실습 1 \n",
    "\n",
    "x = tf.random_uniform([3, 3])\n",
    "\n",
    "print(\"GPU 사용이 가능한가 : \"),\n",
    "## 어떤 주석도 없이 자동적으로 CPU 또는 GPU를 사용할 것인지 정함\n",
    "print(tf.test.is_gpu_available())\n",
    "\n",
    "print(\"텐서가 GPU #0에 있는가 :  \"),\n",
    "print(x.device.endswith('GPU:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On CPU:\n",
      "10 loops: 403.77ms\n"
     ]
    }
   ],
   "source": [
    "# 명시적 장치 배치 실습 1\n",
    "\n",
    "import time\n",
    "\n",
    "def time_matmul(x):\n",
    "  start = time.time()\n",
    "  for loop in range(10):\n",
    "    tf.matmul(x, x)\n",
    "\n",
    "  result = time.time()-start\n",
    "    \n",
    "  print(\"10 loops: {:0.2f}ms\".format(1000*result))\n",
    "\n",
    "\n",
    "# CPU에서 강제실행합니다.\n",
    "print(\"On CPU:\")\n",
    "with tf.device(\"CPU:0\"):\n",
    "  x = tf.random_uniform([1000, 1000])\n",
    "  assert x.device.endswith(\"CPU:0\")\n",
    "  time_matmul(x)\n",
    "\n",
    "# GPU #0가 이용가능시 GPU #0에서 강제실행합니다.\n",
    "if tf.test.is_gpu_available():\n",
    "  with tf.device(\"GPU:0\"): # 또는 GPU:1, GPU:2\n",
    "    x = tf.random_uniform([1000, 1000])\n",
    "    assert x.device.endswith(\"GPU:0\")\n",
    "    time_matmul(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋\n",
    "    - 모델을 훈련시키고 평가 루프를 제공할 간단하고 재사용 가능한 모듈로부터, 복잡한 입력 파이프라인을 구축하기 위해 데이터셋 API사용 권장 \n",
    "    - tf.data.Dataset 객체를 통하여 파이썬 반복문을 사용할 수 있으며, 명시적으로 tf.data.Iterator 객체를 생성할 필요가 없습니다. -> 즉시 실행이 활성화될 때에는 반복자에 대한 논의 신경쓰지 않아도 됨.\n",
    "     \n",
    "    ## 소스 dataset 생성\n",
    "        - Dataset.from_tensors, Dataset.from_tensor_slices 와 같은 팩토리 함수 사용 \n",
    "        - TextLineDataset 또는 TFRecordDataset와 같은 파일로부터 읽어들이는 객체 사용 \n",
    "        \n",
    "    ## 변환 적용\n",
    "        - map, batch, shuffle 과 같은 변환 함수를 사용해 데이터셋의 레코드에 적용하기\n",
    "        - map : 각 요소별 변형\n",
    "        - batch : 전체 데이터셋에 대한 변형 \n",
    "    ## 반복 \n",
    "        - 즉시 실행이 활성화되면 Dataset 객체는 반복이 가능\n",
    "        - Dataset.make_one_shot_iterator() 또는 get_next()와 같은 객체를 호출할 필요가 없다\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소스 데이터 셋 생성 실습 1 \n",
    "\n",
    "ds_tensors = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# CSV 파일을 생성합니다.\n",
    "import tempfile\n",
    "_, filename = tempfile.mkstemp()\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "  f.write(\"\"\"Line 1\n",
    "Line 2\n",
    "Line 3\n",
    "  \"\"\")\n",
    "\n",
    "ds_file = tf.data.TextLineDataset(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환 적용 실습 1 \n",
    "\n",
    "# map의 함수를 squre를 사용(요소별 제곱해주기)\n",
    "# shuffle : 버퍼크기 2로 하여 랜덤으로 replace\n",
    "# batch : 2의 배치 사이즈로 해당 데이터 셋을 combine \n",
    "\n",
    "ds_tensors = ds_tensors.map(tf.square).shuffle(2).batch(2)\n",
    "\n",
    "ds_file = ds_file.batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds_tensors 요소:\n",
      "WARNING:tensorflow:From c:\\users\\bsww201\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflowtest\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:532: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "tf.Tensor([4 1], shape=(2,), dtype=int32)\n",
      "tf.Tensor([16  9], shape=(2,), dtype=int32)\n",
      "tf.Tensor([36 25], shape=(2,), dtype=int32)\n",
      "\n",
      "ds_file 요소:\n",
      "tf.Tensor([b'Line 1' b'Line 2'], shape=(2,), dtype=string)\n",
      "tf.Tensor([b'Line 3' b'  '], shape=(2,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# 반복 실습 1 \n",
    "\n",
    "print('ds_tensors 요소:')\n",
    "for x in ds_tensors:\n",
    "  print(x)\n",
    "\n",
    "print('\\nds_file 요소:')\n",
    "for x in ds_file:\n",
    "  print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
